# ğŸš€ AI-Powered Knowledge Base Search & Enrichment

A lightweight **Retrieval-Augmented Generation (RAG)** system that lets users upload documents, search them in natural language, get AI-generated answers, and receive smart suggestions when information is incomplete.

---

## ğŸ§± Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gradio UI  â”‚ â”€â–¶  â”‚ FastAPI APIâ”‚ â”€â–¶  â”‚ Qdrant DB  â”‚ â”€â–¶  â”‚ LLM Engine â”‚
â”‚ (Frontend) â”‚     â”‚ (Backend)  â”‚     â”‚ (Vectors)  â”‚     â”‚ (Answer +  â”‚
â”‚            â”‚     â”‚            â”‚     â”‚            â”‚     â”‚  Critic)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

* **Frontend:** Gradio (3 tabs â€” File, Collection, Chat)
* **Backend:** FastAPI REST API
* **Vector DB:** Qdrant (semantic search)
* **LLM Layer:** Answer generator + Critic evaluator

---

## âš™ï¸ Functionality

| Feature                | Description                                         |
| ---------------------- | --------------------------------------------------- |
| **Upload Documents**   | Add PDFs or text files via UI or API                |
| **Create Collections** | Group related files for search                      |
| **Link Content**       | Process files into embeddings (BGE-large-en-v1.5)   |
| **Ask Questions**      | Natural language query across documents             |
| **Reranker**           | Improves relevance of retrieved chunks              |
| **Critic Head**        | Evaluates if the answer is complete or uncertain    |
| **Auto-Enrichment**    | Suggests topics or documents to fill knowledge gaps |

---

## ğŸ’¡ How It Works

1. **Upload & Index** â€” Files are embedded using **BGE-large-en-v1.5** and stored in **Qdrant**.
2. **Query** â€” A user asks a natural-language question.
3. **Retrieve** â€” Top-matching chunks are fetched via vector similarity.
4. **Rerank** â€” Results are refined using a **CrossEncoder**.
5. **Generate** â€” The **LLM** produces an answer using retrieved context.
6. **Critic Evaluate** â€” A critic model checks for missing information and suggests enrichment areas.

---

## ğŸ§  Example Output

```json
{
  "answer": "LearnLM is part of Gemini 2.5 designed to infuse AI with learning science principles.",
  "confidence": 0.82,
  "is_relevant": true,
  "critic": {
    "confidence": 0.6,
    "missing_info": "Lacks examples of LearnLM in Google products.",
    "enrichment_suggestions": [
      "Add details about LearnLM applications in Search and Classroom.",
      "Include its underlying learning science principles."
    ]
  }
}
```

---

## ğŸ§© Limitations

| Limitation                        | Reason                                       |
| --------------------------------- | -------------------------------------------- |
| **High Query Latency (~20â€“30s)**  | Sequential model loading and CPU inference   |
| **In-memory Qdrant on HF Spaces** | No persistence between restarts              |
| **Limited Auto-Enrichment**       | Placeholder logic (suggestive, not fetching) |
| **Single-threaded LLM calls**     | Slower for long or multi-query workflows     |

---

## ğŸš€ Next Steps

1. **Optimize Latency** â€” Move to async or batched inference with GPU backend.
2. **Persistent Vector DB** â€” Use managed Qdrant or Pinecone cloud instance.
3. **Expand Enrichment Engine** â€” Integrate Wikipedia / ArXiv fetcher for missing info.
4. **Add Feedback Loop** â€” Allow user rating to fine-tune critic.
5. **Deploy Production-Grade Stack** â€” Split frontend/backend, add auth & caching.

---

## ğŸ Summary

âœ… **End-to-End RAG Pipeline**
âœ… **Structured AI Responses** (Answer + Confidence + Critic)
âœ… **Smart Completeness Detection**
âœ… **Knowledge Enrichment Suggestions**
âœ… **Deployed on Hugging Face with Functional UI**

---

**Built by Nakul Jain**
*Demonstrating applied AI systems design, completeness eva
